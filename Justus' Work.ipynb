{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0adc8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48cfe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data from the MPD slice file\n",
    "with open('mpd.slice.0-999.json') as f:\n",
    "    mpd_data = json.load(f)\n",
    "# Extract playlists from the data\n",
    "playlists = mpd_data[\"playlists\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef78f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the playlist data\n",
    "playlist_df = pd.DataFrame(playlists)\n",
    "\n",
    "# Extract relevant features for clustering\n",
    "X = playlist_df[['name', 'description']].fillna('').apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')\n",
    "X_vect = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccfd7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.cluster import MiniBatchKMeans\n",
    "# k_values = range(1, 100)  # Try cluster numbers from 1 to 10\n",
    "# inertia_values = []\n",
    "# for k in k_values:\n",
    "#     kmeans = MiniBatchKMeans(n_clusters=k, random_state=42)\n",
    "#     kmeans.fit(X_vect)\n",
    "#     inertia_values.append(kmeans.inertia_)\n",
    "# plt.plot(k_values, inertia_values, marker='o')\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('Inertia')\n",
    "# plt.title('Elbow Method for Optimal k')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1cc631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_values = range(2, 100)\n",
    "# best_silhouette_score = -1\n",
    "# best_k = None\n",
    "# for k in k_values:\n",
    "#     minibatch_kmeans = MiniBatchKMeans(n_clusters=k, random_state=42)\n",
    "#     cluster_labels = minibatch_kmeans.fit_predict(X_vect)\n",
    "#     silhouette_avg = silhouette_score(X_vect, cluster_labels)\n",
    "#     print(f\"Number of clusters: {k}, Silhouette Score: {silhouette_avg}\")\n",
    "#     if silhouette_avg > best_silhouette_score:\n",
    "#         best_silhouette_score = silhouette_avg\n",
    "#         best_k = k\n",
    "\n",
    "# print(f\"Best number of clusters: {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97b9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A general rule of thumb is that a silhouette score above 0.5 indicates a good clustering, \n",
    "#a silhouette score below 0.25 indicates a bad clustering,\n",
    "#and a silhouette score between 0.25 and 0.5 indicates a fair clustering.\n",
    "\n",
    "#40 clusters has a score of 0.5108932664557817, and seems to be a good elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9494079",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Vetting_Playlist.json', 'r') as file:\n",
    "    # Read the contents\n",
    "    json_data = file.read()\n",
    "    # Parse the JSON\n",
    "    vetting = json.loads(json_data)\n",
    "    \n",
    "playlist_data = {\n",
    "    'name': [vetting['name']],\n",
    "    'description': [vetting.get('description', '')]  # Assuming description may be missing\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the playlist data\n",
    "playlist_df = pd.DataFrame(playlist_data)\n",
    "\n",
    "# Extract relevant features for clustering\n",
    "X = playlist_df[['name', 'description']].fillna('').apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_df=1.0, min_df=1, stop_words='english')\n",
    "V_vect = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52939bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but MiniBatchKMeans is expecting 157 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8364\\89652705.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mminibatch_kmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcluster_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminibatch_kmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_vect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mminibatch_kmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV_vect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, sample_weight)\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2147\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2148\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m   1008\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1 features, but MiniBatchKMeans is expecting 157 features as input."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=40, random_state=42)\n",
    "cluster_labels = minibatch_kmeans.fit_predict(X_vect)\n",
    "minibatch_kmeans.predict(V_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259d1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632acca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
